<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Simplified Example</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"
            crossorigin="anonymous"></script>
    <script src="https://mrdoob.github.io/stats.js/build/stats.min.js"></script>
    <style>
        body {
            background-color: cyan;
        }
        .mirror {
            transform: scaleX(-1);
        }
    </style>
</head>
<body>
<div class="container">
    <div>
        <h2>Sender</h2>
        <div>
            <label for="devices">Select your camera device: </label>
            <select name="devices" id="devices" class="senderControls"></select>
            <br>
            <p>Select a resolution to begin camera capture:</p>
            <button id="qvga" class="senderControls">QVGA</button>
            <button id="vga" class="senderControls">VGA</button>
            <button id="hd" class="senderControls">HD</button>
            <button id="uhd" class="senderControls">UHD</button>

        </div>
    </div>
    <br>
    <div>
        <canvas id="transparent_self" class="mirror"></canvas>
        <div id="senderStats">
            <!--div>
                <p id="senderFps"></p>
                <br>
            </div-->
        </div>
    </div>
    <br>
    <button id="call" class="senderControls" disabled >Send through peerConnection</button>
    <br>
    <div>
        <h2>Receiver</h2>
        <video autoplay muted playsinline></video>
        <canvas id="transparent_receiver"></canvas>
        <div id="receiverStats">
            <!--div>
                <p id="receiverFps"></p>
                <br>
            </div-->
        </div>

    </div>
    <script type="module">
        const selfieCanvas = document.querySelector('canvas#transparent_self');
        // const receiverCanvas = document.querySelector('canvas#transparent_receiver');

        const deviceSelect = document.querySelector('select#devices');

        const qvgaBtn = document.querySelector('button#qvga');
        const vgaBtn = document.querySelector('button#vga');
        const hdBtn = document.querySelector('button#hd');
        const uhdBtn = document.querySelector('button#uhd');

        const callBtn = document.querySelector('button#call');

        // const senderFpsP = document.querySelector('p#senderFps');
        // const receiverFpsP = document.querySelector('p#receiverFps');


        let videoWidth = 640;
        let videoHeight = 480;

        const FRAME_RATE = 30;

        let videoDevices = [];

        // Transparency
        function addAplha(imageData) {

            let data = imageData.data;
            const gFloor = 105;         // consider any green above this value to be transparent
            const rbCeiling = 80;       // highest value for red and blue to be considered transparent

            for (let r = 0, g = 1, b = 2, a = 3; a < data.length; r += 4, g += 4, b += 4, a += 4) {
                if (data[r] <= rbCeiling && data[b] <= rbCeiling && data[g] >= gFloor)
                    data[a] = 0;
            }
            return imageData;
        }


        // Receiver
        const receiverOffScreen = new OffscreenCanvas(1,1);
        const receiverCtx = receiverOffScreen.getContext("2d");

        // stats setup
        // let lastFrameTime = new Date();
        const recStats = new Stats();
        document.querySelector('div#receiverStats').appendChild(recStats.dom);
        recStats.dom.style.position = 'relative';
        recStats.dom.style.display = 'none';

        function addTransparency(frame, controller){
            recStats.begin();

            const height = frame.codedHeight;
            const width = frame.codedWidth;

            receiverOffScreen.height = height;
            receiverOffScreen.width = width;

            receiverCtx.drawImage(frame, 0, 0, width, height);
            let imageData = receiverCtx.getImageData(0, 0, width, height);
            let transparentImageData = addAplha(imageData);
            receiverCtx.putImageData(transparentImageData, 0, 0);

            const newFrame = new VideoFrame(receiverOffScreen);
            controller.enqueue(newFrame);
            frame.close();

            // FPS calcs
            // const now = new Date();
            // const fps = (1000/(now-lastFrameTime)).toFixed();
            // receiverFpsP.innerHTML = `FPS: ${fps}`;
            // lastFrameTime = now;
            recStats.end();
        }

        document.addEventListener('offer', async e => {
            console.debug(e.detail);

            const pc = new RTCPeerConnection();

            pc.ontrack = async e => {
                console.debug(e);
                const {track} = e;

                const processor = new MediaStreamTrackProcessor({track});

                const generator = new MediaStreamTrackGenerator({kind: 'video'});
                const transparentStream = new MediaStream([generator]);
                document.querySelector('video').srcObject = transparentStream;

                await processor.readable.pipeThrough(new TransformStream({
                    transform: (frame, controller) => addTransparency(frame, controller)
                })).pipeTo(generator.writable);

            };

            document.addEventListener('candidate', async e => {
                console.debug(e.detail);
                await pc.addIceCandidate(e.detail.candidate);
            });

            await pc.setRemoteDescription(e.detail);

            window.receiverPc = pc;

            const answer = await pc.createAnswer();
            await pc.setLocalDescription(answer);

            const toSenderEvent = new CustomEvent('answer', {detail: answer});
            document.dispatchEvent(toSenderEvent);

            recStats.dom.style.display = 'block';

        });

        // Sender
        async function sendVideo(stream) {
            console.log("peerConnection starting");

            const track = stream.getVideoTracks()[0];

            const pc = new RTCPeerConnection();
            pc.addTrack(track, stream);
            window.sendStream = stream;         // for debugging

            pc.onicecandidate = candidate => {
                const toReceiverEvent = new CustomEvent('candidate', {detail: candidate});
                document.dispatchEvent(toReceiverEvent);
            };

            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);

            const toReceiverEvent = new CustomEvent('offer', {detail: offer});
            document.dispatchEvent(toReceiverEvent);


            document.addEventListener('answer', async e => {
                console.debug(e.detail);
                await pc.setRemoteDescription(e.detail);
            });
        }


        // Segment
        const ctx = selfieCanvas.getContext('2d');

        const offscreen = new OffscreenCanvas(1, 1);
        const offscreenCtx = offscreen.getContext('2d');

        const selfieSegmentation = new SelfieSegmentation({
            locateFile: (file) => {
                return `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`;
            }
        });
        selfieSegmentation.setOptions({
            modelSelection: 1,
        });


        const senderStats = new Stats();
        document.querySelector('div#senderStats').appendChild(senderStats.dom);
        senderStats.dom.style.position = 'relative';
        senderStats.dom.style.display = 'none';

        async function segment(frame, controller) {
            const height = frame.codedHeight;
            const width = frame.codedWidth;

            offscreen.height = height;
            offscreen.width = width;

            offscreenCtx.drawImage(frame, 0, 0, width, height);

            // stats setup
            // let lastTime = new Date();
            senderStats.begin();

            await selfieSegmentation.onResults(results => {
                ctx.save();
                ctx.clearRect(0, 0, width, height);
                ctx.drawImage(results.segmentationMask, 0, 0,
                    width, height);

                // Only overwrite existing pixels with green.
                ctx.globalCompositeOperation = 'source-out'; // 'source-in';
                ctx.fillStyle = '#00FF00';
                ctx.fillRect(0, 0, width, height);

                // Only overwrite missing pixels.
                ctx.globalCompositeOperation = 'destination-atop';
                ctx.drawImage(
                    results.image, 0, 0, width, height);
                ctx.restore();

                const newFrame = new VideoFrame(selfieCanvas);
                controller.enqueue(newFrame);
                frame.close();

                ctx.save();
                // Add the transparency for selfie display
                let imageData = ctx.getImageData(0, 0, width, height);
                let transparentImageData = addAplha(imageData);
                ctx.putImageData(transparentImageData, 0, 0);

                ctx.restore();

                // FPS calcs
                // const now = new Date();
                // const fps = (1000/(now-lastTime)).toFixed();
                // senderFpsP.innerHTML = `FPS: ${fps}`;
                // lastTime = now;
                senderStats.end();

            });
            await selfieSegmentation.send({image: offscreen});
        }

        // Get Video
        async function getVideo(width, height) {
            // Use the last res when changing cameras
            if(!width){
                width = videoWidth;
                height = videoHeight;
            }
            else{
                videoHeight = height;
                videoWidth = width;
            }


            // clean up resources if switching sources
            if(window.stream)
                window.stream.getTracks().forEach(track=>track.stop());

            console.log(`Getting ${width}x${height} video`);

            selfieCanvas.height = height;
            selfieCanvas.width = width;

            const videoSource = videoDevices[deviceSelect.selectedIndex || 0]?.deviceId;

            const stream = await navigator.mediaDevices.getUserMedia(
                {
                    video:
                        {
                            height: height, width: width, frameRate: FRAME_RATE,
                            deviceId: videoSource ? {exact: videoSource} : undefined
                        }
                });

            window.stream = stream;
            console.log(`Capture camera with device ${stream.getTracks()[0].label}`);
            callBtn.disabled = false;

            const generator = new MediaStreamTrackGenerator({kind: 'video'});

            let [track] = stream.getVideoTracks();

            const processor = new MediaStreamTrackProcessor({track});
            let sendStream = new MediaStream([generator]);

            callBtn.onclick = async ()=> {
                // Disable controls since the peerConnection won't update
                // ToDo: replace track to allow cam switch when peerConnection is open
                document.querySelectorAll('.senderControls').forEach(element=>element.disabled = true);
                await sendVideo(sendStream);
            };

            senderStats.dom.style.display = 'block';    // show stats

            await processor.readable.pipeThrough(new TransformStream({
                transform: (frame, controller) => segment(frame, controller)
            })).pipeTo(generator.writable);
        }

        async function start() {
            // allow camera selection
            let devices = await navigator.mediaDevices.enumerateDevices();
            videoDevices = devices.filter(device => device.kind === 'videoinput');
            videoDevices.forEach(device => {
                const option = document.createElement('option');
                option.text = device.label;
                deviceSelect.appendChild(option);
            });

            deviceSelect.onchange = ()=>getVideo();

            qvgaBtn.onclick = () => getVideo(320, 240);
            vgaBtn.onclick = () => getVideo(640, 480);
            hdBtn.onclick = () => getVideo(1280, 720);
            uhdBtn.onclick = () => getVideo(1920, 1080);
        }
        start().catch(err => console.error(err));
    </script>
</div>
</body>
</html>
